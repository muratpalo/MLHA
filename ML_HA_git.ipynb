{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e348aed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jenni\\AppData\\Roaming\\Python\\Python39\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc087a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "secom_df = np.loadtxt('./secom.data', dtype=str) \n",
    "secom_df = pd.DataFrame(preprocessing.scale(secom_df)) #scaling and Data Frame\n",
    "\n",
    "target = np.loadtxt('./secom_labels.data', dtype=str)\n",
    "\n",
    "target = pd.DataFrame(target) #Data Frame\n",
    "times = target[2].str.split(':', expand=True)[0]\n",
    "time_df = pd.DataFrame(times)\n",
    "target = target[0].astype(int)\n",
    "time_df['FPY']=target\n",
    "labels_df=target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d06b98",
   "metadata": {},
   "source": [
    "How many observations and features are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3d0eaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features (1567, 590)\n",
      "time (1567,)\n",
      "labels (1567,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1    1463\n",
       " 1     104\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('features',secom_df.shape) #590 features, 1567 observations\n",
    "print('time',times.shape)\n",
    "print('labels',labels_df.shape)\n",
    "\n",
    "#sns.histplot(data = labels_df, color= 'grey')\n",
    "labels_df.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a006ef81",
   "metadata": {},
   "source": [
    "look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a0a2258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1567 entries, 0 to 1566\n",
      "Columns: 590 entries, 0 to 589\n",
      "dtypes: float64(590)\n",
      "memory usage: 7.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(secom_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e169ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>580</th>\n",
       "      <th>581</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.223879</td>\n",
       "      <td>0.847825</td>\n",
       "      <td>-0.434320</td>\n",
       "      <td>0.033405</td>\n",
       "      <td>-0.050354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.561266</td>\n",
       "      <td>0.265504</td>\n",
       "      <td>0.509501</td>\n",
       "      <td>1.127696</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.118661</td>\n",
       "      <td>-0.204825</td>\n",
       "      <td>-0.093178</td>\n",
       "      <td>-0.197050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.105015</td>\n",
       "      <td>-0.382054</td>\n",
       "      <td>1.012583</td>\n",
       "      <td>0.152382</td>\n",
       "      <td>-0.059776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197330</td>\n",
       "      <td>0.321317</td>\n",
       "      <td>0.456708</td>\n",
       "      <td>0.022567</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194011</td>\n",
       "      <td>1.260949</td>\n",
       "      <td>0.530034</td>\n",
       "      <td>0.406549</td>\n",
       "      <td>0.444564</td>\n",
       "      <td>0.384936</td>\n",
       "      <td>-0.959868</td>\n",
       "      <td>0.411722</td>\n",
       "      <td>0.250045</td>\n",
       "      <td>1.156320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.112023</td>\n",
       "      <td>0.797316</td>\n",
       "      <td>-0.479135</td>\n",
       "      <td>0.683141</td>\n",
       "      <td>-0.047691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.902153</td>\n",
       "      <td>0.254341</td>\n",
       "      <td>-0.260740</td>\n",
       "      <td>0.326974</td>\n",
       "      <td>...</td>\n",
       "      <td>3.020445</td>\n",
       "      <td>-0.172375</td>\n",
       "      <td>-1.262377</td>\n",
       "      <td>0.022257</td>\n",
       "      <td>0.014371</td>\n",
       "      <td>0.029823</td>\n",
       "      <td>2.990196</td>\n",
       "      <td>3.625906</td>\n",
       "      <td>3.320359</td>\n",
       "      <td>-0.179091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.349640</td>\n",
       "      <td>-0.198431</td>\n",
       "      <td>-0.051316</td>\n",
       "      <td>-1.101992</td>\n",
       "      <td>-0.051060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500993</td>\n",
       "      <td>-0.013563</td>\n",
       "      <td>0.342999</td>\n",
       "      <td>-0.764920</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.319886</td>\n",
       "      <td>-0.275485</td>\n",
       "      <td>-0.322096</td>\n",
       "      <td>-0.292164</td>\n",
       "      <td>-0.362049</td>\n",
       "      <td>-0.283326</td>\n",
       "      <td>-0.101862</td>\n",
       "      <td>-0.178870</td>\n",
       "      <td>-0.308194</td>\n",
       "      <td>-0.275158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.241679</td>\n",
       "      <td>0.087330</td>\n",
       "      <td>1.112384</td>\n",
       "      <td>-0.158208</td>\n",
       "      <td>-0.047280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.114865</td>\n",
       "      <td>0.187365</td>\n",
       "      <td>0.544697</td>\n",
       "      <td>-0.149489</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.905014</td>\n",
       "      <td>26.858657</td>\n",
       "      <td>27.062785</td>\n",
       "      <td>26.904758</td>\n",
       "      <td>-0.101862</td>\n",
       "      <td>-0.178870</td>\n",
       "      <td>-0.308194</td>\n",
       "      <td>-0.275158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 590 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4    5         6         7    \\\n",
       "0  0.223879  0.847825 -0.434320  0.033405 -0.050354  0.0 -0.561266  0.265504   \n",
       "1  1.105015 -0.382054  1.012583  0.152382 -0.059776  0.0  0.197330  0.321317   \n",
       "2 -1.112023  0.797316 -0.479135  0.683141 -0.047691  0.0 -0.902153  0.254341   \n",
       "3 -0.349640 -0.198431 -0.051316 -1.101992 -0.051060  0.0  0.500993 -0.013563   \n",
       "4  0.241679  0.087330  1.112384 -0.158208 -0.047280  0.0 -0.114865  0.187365   \n",
       "\n",
       "        8         9    ...       580       581       582        583  \\\n",
       "0  0.509501  1.127696  ...       NaN       NaN  0.118661  -0.204825   \n",
       "1  0.456708  0.022567  ...  0.194011  1.260949  0.530034   0.406549   \n",
       "2 -0.260740  0.326974  ...  3.020445 -0.172375 -1.262377   0.022257   \n",
       "3  0.342999 -0.764920  ... -0.319886 -0.275485 -0.322096  -0.292164   \n",
       "4  0.544697 -0.149489  ...       NaN       NaN -5.905014  26.858657   \n",
       "\n",
       "         584        585       586       587       588       589  \n",
       "0  -0.093178  -0.197050       NaN       NaN       NaN       NaN  \n",
       "1   0.444564   0.384936 -0.959868  0.411722  0.250045  1.156320  \n",
       "2   0.014371   0.029823  2.990196  3.625906  3.320359 -0.179091  \n",
       "3  -0.362049  -0.283326 -0.101862 -0.178870 -0.308194 -0.275158  \n",
       "4  27.062785  26.904758 -0.101862 -0.178870 -0.308194 -0.275158  \n",
       "\n",
       "[5 rows x 590 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secom_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3011f466",
   "metadata": {},
   "source": [
    "How do you plan to handle missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78ee95f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(secom_df.isna().any().any()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36fa8e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1567, 558)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.elektormagazine.de/articles/datenanalyse-und-knstliche-intelligenz-in-python\n",
    "na_cols = [col for col in secom_df.columns if secom_df[col].isnull().sum() / len(secom_df) > 0.4]\n",
    "secom_df = secom_df.drop(na_cols, axis=1)\n",
    "secom_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1898b45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputer = SimpleImputer(strategy='mean')\n",
    "imputer = KNNImputer(n_neighbors=12, weights=\"uniform\")\n",
    "secom_imputed = pd.DataFrame(imputer.fit_transform(secom_df))\n",
    "secom_imputed.columns = secom_df.columns\n",
    "secom_df=secom_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c50d557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(secom_df.isna().any().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5c0a32",
   "metadata": {},
   "source": [
    "Check for trends and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee097c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "secom_df.describe() #there are outliers\n",
    "#Standartesierung Notwendig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61004b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.array(secom_df)[:,0:20]).hist(figsize=(12, 10), bins=30, edgecolor=\"black\")\n",
    "plt.subplots_adjust(hspace=0.7, wspace=0.4)\n",
    "#es gibt Konstanten #sehe auch in der Beschreibung der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a4e297",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entferne Konstanten\n",
    "secom_df=secom_df.loc[:, (secom_df != secom_df.iloc[0]).any()]\n",
    "secom_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be920c7c",
   "metadata": {},
   "source": [
    "Are there redundant features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6a31d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(secom_df.corr())\n",
    "#es existiert eine Korrelation, also es gibt in den Daten redundante Werte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b186fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.projectpro.io/recipes/drop-out-highly-correlated-features-in-python#mcetoc_1g0c4fnd4a\n",
    "df= secom_df\n",
    "cor_matrix = df.corr(method=\"spearman\").abs()\n",
    "#print(cor_matrix)\n",
    "upper_tri = cor_matrix.where(np.triu(np.ones(cor_matrix.shape),k=1).astype(bool))\n",
    "upper_tri.set_axis(list(range(0,secom_df.shape[1])), axis=1,inplace=True)\n",
    "#print(upper_tri)\n",
    "to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > 0.99)]\n",
    "secom_df = df.drop(df.columns[to_drop], axis=1) # geht nur ein mal\n",
    "#print(secom_df.head())\n",
    "secom_df.shape #Redundante Werte sind entfernt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad6ac44",
   "metadata": {},
   "source": [
    "feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab1df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA feature selection for numeric input and categorical output\n",
    "k=40\n",
    "# define feature selection ANOVA entspricht Ftest\n",
    "fs = SelectKBest(score_func=f_classif, k=k)\n",
    "# apply feature selection \n",
    "secom_df = pd.DataFrame(fs.fit_transform(secom_df, labels_df))\n",
    "print(secom_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ea3ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "secom_df.keys() #->key falsch gesetzt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f528ab",
   "metadata": {},
   "source": [
    "Aufgabe 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ddac27",
   "metadata": {},
   "source": [
    "Are there specific times with a higher rate of errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f236719",
   "metadata": {},
   "outputs": [],
   "source": [
    "target2 = np.loadtxt('./secom_labels.data', dtype=str)\n",
    "target2 = pd.DataFrame(target2) #Data Frame\n",
    "target2.value_counts()\n",
    "times2 = target2[2].str.split(':', expand=True)[0]\n",
    "times2 = pd.DataFrame(times2)\n",
    "target2 = target2[0]\n",
    "times2['FPY']=target2\n",
    "\n",
    "plt.hist(times2[times2['FPY'] == '-1'][0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcae11c",
   "metadata": {},
   "source": [
    "!!!cross validierung, seed!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5b50b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(secom_df, labels_df, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd24771",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Features Shape:', X_train.shape)\n",
    "print('Training Labels Shape:', y_train.shape)\n",
    "print('Testing Features Shape:', X_test.shape)\n",
    "print('Testing Labels Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c585b3b",
   "metadata": {},
   "source": [
    "Develop a prediction model for First Pass Yield (FPY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3477358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=10000,random_state=0)\n",
    "lr1 = lr.fit(X_train, y_train)\n",
    "y_pred_lr= lr1.predict(X_test)\n",
    "\n",
    "\n",
    "lasso = linear_model.Lasso(alpha=0.1, family=\"binomial\")\n",
    "lasso1 = lasso.fit(X_train, y_train)\n",
    "y_pred_lasso= lasso1.predict(X_test)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf1 = rf.fit(X_train,y_train)\n",
    "y_pred_rf = rf1.predict(X_test)\n",
    "\n",
    "knc = KNeighborsClassifier()\n",
    "knc1 = knc.fit(X_train,y_train)\n",
    "y_pred_knc= knc1.predict(X_test)\n",
    "\n",
    "gbm = GradientBoostingClassifier()\n",
    "gbm1 = gbm.fit(X_train,y_train)\n",
    "y_pred_gbm= gbm1.predict(X_test)\n",
    "\n",
    "b = BaggingClassifier()\n",
    "b1 = b.fit(X_train,y_train)\n",
    "y_pred_b= b1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bef140",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy score train\")\n",
    "print(\"LogisticRegression: {0}\".format(lr1.score(X_train,y_train)))\n",
    "print(\"LassoRegression: {0}\".format(lasso1.score(X_train,y_train)))\n",
    "print(\"RandomForestClassifier: {0}\".format(rf1.score(X_train,y_train)))\n",
    "print(\"KNeighborsClassifier: {0}\".format(knc1.score(X_train,y_train)))\n",
    "print(\"GradientBoostingClassifier: {0}\".format(gbm1.score(X_train,y_train)))\n",
    "print(\"BaggingClassifier: {0}\".format(b1.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef9e79b",
   "metadata": {},
   "source": [
    "Which of the process features are important for the prediction of First Pass\n",
    "Yield (FPY)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd0989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM\n",
    "gbm_importance = gbm.feature_importances_\n",
    "gbm_ranked_indices = np.argsort(gbm_importance)[::-1]\n",
    "\n",
    "#Random Forest\n",
    "rf_importance = rf.feature_importances_\n",
    "rf_ranked_indices = np.argsort(rf_importance)[::-1]\n",
    "\n",
    "#Boosting\n",
    "b_importance = np.mean([tree.feature_importances_ for tree in b.estimators_], axis=0)\n",
    "b_ranked_indices = np.argsort(b_importance)[::-1]\n",
    "\n",
    "# printing results in a table\n",
    "importance_results = pd.DataFrame(index=range(1,16), \n",
    "                                  columns=pd.MultiIndex.from_product([['GBM','RF','B'],['Feature #','Importance']]))\n",
    "importance_results.index.name = 'Rank'\n",
    "importance_results.loc[:,'GBM'] =  list(zip(gbm_ranked_indices[:15], \n",
    "                                            gbm_importance[gbm_ranked_indices[:15]]))\n",
    "importance_results.loc[:,'RF'] =  list(zip(rf_ranked_indices[:15], \n",
    "                                           rf_importance[rf_ranked_indices[:15]]))\n",
    "importance_results.loc[:,'B'] =  list(zip(b_ranked_indices[:15], \n",
    "                                           b_importance[b_ranked_indices[:15]]))\n",
    "print(importance_results)\n",
    "\n",
    "#Auswertung fehlt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c01f80",
   "metadata": {},
   "source": [
    "Assess the accuracy of the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1c91a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy score train\")\n",
    "print(\"LogisticRegression: {0}\".format(lr1.score(X_train,y_train)))\n",
    "print(\"LassoRegression: {0}\".format(lasso1.score(X_train,y_train)))\n",
    "print(\"RandomForestClassifier: {0}\".format(rf1.score(X_train,y_train)))\n",
    "print(\"KNeighborsClassifier: {0}\".format(knc1.score(X_train,y_train)))\n",
    "print(\"GradientBoostingClassifier: {0}\".format(gbm1.score(X_train,y_train)))\n",
    "print(\"BaggingClassifier: {0}\".format(b1.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095b85ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy score test\")\n",
    "print(\"LogisticRegression: {0}\".format(accuracy_score(y_test,y_pred_lr)))\n",
    "#print(\"LassoRegression: {0}\".format(accuracy_score(y_test,y_pred_lasso)))\n",
    "print(\"RandomForestClassifier: {0}\".format(accuracy_score(y_test,y_pred_rf)))\n",
    "print(\"KNeighborsClassifier: {0}\".format(accuracy_score(y_test,y_pred_knc)))\n",
    "print(\"GradientBoostingClassifier: {0}\".format(accuracy_score(y_test,y_pred_gbm)))\n",
    "print(\"BaggingClassifier: {0}\".format(accuracy_score(y_test,y_pred_b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86886af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03076b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
